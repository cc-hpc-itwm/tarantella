Features
========

Distributed data parallel training
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. todo::

  * what is it?
  * thinks to know/mind:
  
    * global vs local batch size
    * adaption of learning rate
    * BatchNorm layers (computed over local batch size)
    * the notion of ranks -> c.f. advanced topics

Distributed data sets
^^^^^^^^^^^^^^^^^^^^^
