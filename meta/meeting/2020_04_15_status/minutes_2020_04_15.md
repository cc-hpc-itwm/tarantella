## date: 15/04/2020
## time: 15.00 -- 17:00
## attendees:
  * Alexandra Carpen-Amarie [ACA]
  * Martin Kuehn [MK]
  * Peter Labus [PL]

## Status Meeting

### Model parallelism

[MK] will start looking into distributed convolutions (and possbily other layers) for a model parallel U-Net

### Benchmark results finding tarantella overheads on GPU Cluster
* Results in  
  - https://gitlab.itwm.fraunhofer.de/labus/gpionnx_experiments
  - gpionnx_experiments/tensorflow/kuehn_06042020/
* C++ side of the framework does not introduce significant overheads on GPUs
  - crippled C experiments (disable all work done in the C++ implementation/SynchCommunicator) vs. tarantella full
* Using empty py_functions in the TF graph removes the overhead completely
  - crippledpy vs. tarantella_full
* Adding work into py_functions (accessing the gradients) results in a large overhead
  - crippledpy_scale vs. crippledpy
* Creating and initializing reduced gradient arrays and copying them back to TF represents ~3% overhead over the iteration time
* Horovod vs. Tarantella
  - Results in gpionnx_experiments/tensorflow/kuehn_27032020/horovod
  - Horovod has zero overhead on single rank for GPU
  - Overhead Tarantella versus Horovod seems to be approx. constant per iteration over ranks
  - **TODO** complete Horovod vs. Tarantella
* put tag "v0.1" on benchmarked version  

### Open merge requests
* Test allreduce (cf. !2)
  - TODO: create script to run all tests manually [ACA]
  - TODO: fix Segment size in AllreduceButterfly test [MK]
  - TODO: rebase on master [ACA]
  - TODO: create merge request for the GPIGroup implementation and tests [ACA]
  - TODO: fix failing tests [MK]
* refactoring SynchCommunicator (cf !3)
  - merged
